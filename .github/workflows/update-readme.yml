name: Update README with Project Links

on:
  push:
  schedule:
    - cron: '0 0 1 * *'  # Monthly on the 1st

permissions:
  contents: write

env:
  TOP_N: 5  # Change this number to control how many repos show

jobs:
  update-readme:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Skip if last commit was < 24 hours ago
      - name: Check last commit time
        run: |
          LAST_COMMIT_TIME=$(git log -1 --format=%ct)
          CURRENT_TIME=$(date +%s)
          TIME_DIFF=$((CURRENT_TIME - LAST_COMMIT_TIME))
          if [ $TIME_DIFF -lt 86400 ]; then
            echo "Last commit was less than 24 hours ago. Skipping update."
            exit 0
          fi

      # Step 3: Extract existing project links (keep your custom display names)
      - name: Extract existing project links
        run: |
          awk '/^## Projects/{flag=1; next} /^## /{flag=0} flag' README.md > existing_projects.md || true

      # Step 4: Fetch all public repos sorted by updated desc and select top N excluding forks and your repo itself
      - name: Fetch top N public repos from GitHub
        run: |
          curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/users/${{ github.repository_owner }}/repos?type=public&per_page=100&sort=updated&direction=desc" \
          | jq -r --argjson n $TOP_N \
            'map(select(.fork == false and .name != "Kentthou")) | .[:$n][] | "- [\(.name)](\(.html_url))"' > fetched_projects.md

      # Step 5: Merge, deduplicate by URL (keep custom names), filter only top N, and sort alphabetically
      - name: Merge and sort project links cleanly
        run: |
          # Extract your preferred display names
          awk -F'[()]' '/^- \[.*\]\(.*\)/ { print }' existing_projects.md > preferred_existing.md

          # Merge preferred + fetched links
          cat preferred_existing.md fetched_projects.md | grep -v '^\s*$' > merged_all.md

          # Deduplicate by URL (preserve first occurrence to keep preferred names)
          awk '{
            match($0, /\(https:\/\/github\.com\/[^)]+\)/, arr)
            url = arr[0]
            if (!seen[url]++) print $0
          }' merged_all.md > deduped.md

          # Keep only URLs from the top N fetched repos
          awk 'NR==FNR { urls[$0]; next } {
            match($0, /\(https:\/\/github\.com\/[^)]+\)/, arr)
            if (arr[0] in urls) print $0
          }' <(awk '{match($0, /\(https:\/\/github\.com\/[^)]+\)/, arr); print arr[0]}' fetched_projects.md) deduped.md > topn_filtered.md

          # Sort alphabetically by display name (case-insensitive)
          sort -f topn_filtered.md > sorted_projects.md

          # Replace README '## Projects' section with new list
          awk '
            BEGIN { in_projects=0 }
            /^## Projects/ {
              print
              print ""  # blank line after header
              while ((getline line < "sorted_projects.md") > 0) print line
              close("sorted_projects.md")
              print ""  # blank line before next section
              in_projects=1
              next
            }
            in_projects && /^## / { in_projects=0 }
            !in_projects
          ' README.md > README.tmp

          mv README.tmp README.md

      # Step 6: Commit changes safely
      - name: Commit changes
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git add README.md
          git commit -m "Update README with top $TOP_N newest project links" || echo "No changes to commit"
          git pull --rebase origin main || true
          git push origin main

      # Step 7: Clean up temporary files
      - name: Clean up temporary files
        run: rm -f *.md *.txt
